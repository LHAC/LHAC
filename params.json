{"name":"LHAC","tagline":"Practical Inexact Proximal Quasi-Newton Method with Global Complexity Analysis","body":"# LHAC\r\nby Xiaocheng Tang [http://goo.gl/6QuMl]  \r\n\r\n**LHAC** implements the algorithm -- <b> L</b>ow rank <b>H</b>essian <b>A</b>pproximation in <b>A</b>ctive-set <b>C</b>oordinate descent ([paper](http://goo.gl/ERZb3i))  -- for minimizing composite functions, i.e.,  \r\n\r\n* `min f(x) + g(x)`  \r\n\r\nwhere `f(x)` can be any _smooth_ function, i.e., _logistic loss_, _square loss_, etc., and `g(x)` is assumed to be _simple_, i.e., `l1-norm`, `l1/l2-norm`, etc. There are for now two varieties of LHAC:\r\n\r\n* [**Lcc**](http://goo.gl/KqrYSl): LHAC for Composite minimization \r\n* [**Lss**](http://goo.gl/oedlP0): LHAC for Sparse inverse covariance Selection\r\n\r\nBoth of the two packages implement LHAC, but are targeted at different sets of problems. In particular, **Lss** is specifically coded for the _sparse inverse covariance selection_ problem and mainly handles variables in a matrix that is constrained to be positive definite, whereas **Lcc** is implemented for general composite minimization that treats variables as a vector with no extra constraints.\r\n\r\nFor more details on the two packages, please visit their repositories on Github.\r\n\r\n## Citation\r\nIf you use LHAC in your research, please cite the following paper:\r\n\r\n* Katya Scheinberg and Xiaocheng Tang, _Practical Inexact Proximal Quasi-Newton Method with Global Complexity Analysis_, submitted, 2014  ([BibTex](http://goo.gl/fVJgWN))\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}